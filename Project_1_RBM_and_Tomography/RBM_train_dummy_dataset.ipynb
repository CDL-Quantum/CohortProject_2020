{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T09:34:12.950481Z",
     "start_time": "2020-06-03T09:34:12.945954Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from RBM_helper import RBM\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Epochs, Batch Size and GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T09:34:52.363302Z",
     "start_time": "2020-06-03T09:34:52.360043Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 200\n",
    "gpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dummy Training Set\n",
    "\n",
    "For a first test we define a training set, which contains the strings `[1,0,1,0,...]` and `[0,1,0,1,...]` with equal probability and we will train an RBM on them.\n",
    "After the training we can sample from the RBM and we should get these two strings with equal probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T09:36:46.746905Z",
     "start_time": "2020-06-03T09:36:46.734187Z"
    }
   },
   "outputs": [],
   "source": [
    "#DUMMY TRAINING SET\n",
    "# ------------------------------------------------------------------------------\n",
    "#define a simple training set and check if rbm.draw() returns this after training.\n",
    "data = np.array([[1,0,1,0,1,0,1,0,1,0]]*1000 + [[0,1,0,1,0,1,0,1,0,1]]*1000)\n",
    "np.random.shuffle(data)\n",
    "data = torch.FloatTensor(data)\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define RBM and Data Loader\n",
    "\n",
    "We define the RBM and choose 10 visible units (because the input data is 10 dimensional) and 10 hidden units. `k=1` indicates how many Gibbs sampling steps we make during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T09:34:58.135190Z",
     "start_time": "2020-06-03T09:34:53.992405Z"
    }
   },
   "outputs": [],
   "source": [
    "vis = len(data[0]) #input dimension\n",
    "\n",
    "rbm = RBM(n_vis = vis, n_hin = vis, k=1, gpu = gpu)\n",
    "if gpu:\n",
    "    rbm = rbm.cuda()\n",
    "    all_spins = all_spins.cuda()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T09:34:58.135190Z",
     "start_time": "2020-06-03T09:34:53.992405Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # What does this code do? (next 5 lines?)\n",
    "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "    print(epoch)\n",
    "    momentum = 1 - 0.1*(epochs-epoch)/epochs #starts at 0.9 and goes up to 1\n",
    "    lr = (0.1*np.exp(-epoch/epochs*10))+0.0001\n",
    "    rbm.train(train_loader, lr = lr, momentum = momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from trained RBM\n",
    "\n",
    "Draw 10 samples from RBM and print them. If the training was successful, they should be one of the training samples. You can also increase the number of samples and count how often each sample appears. They should be equally likely, because they are also equally likely in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T09:41:28.136800Z",
     "start_time": "2020-06-03T09:41:28.109753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAW SAMPLES\n",
      "[1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "[0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "[1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "[1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "[1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "[0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "[0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "[0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "[1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "[0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "nr_samples = 10\n",
    "print('DRAW SAMPLES')\n",
    "for i in range(nr_samples):\n",
    "    a = rbm.draw_sample(10)\n",
    "    print(a.detach().numpy())   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
